{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make sure dataset is downloaded and extracted `@repoDirectory/data/raw/font-dataset` -> this path should be at the repo root\n",
    "<mark> make sure that these <mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install all dependencies\n",
    "%pip install -r \"../../requirements.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "### importing libraries\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import hough_line, hough_line_peaks # to detect the orientation of the text in image \n",
    "from skimage.feature import canny\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the tutorial\n",
    "def plot_change(img_before, img_after, effect):\n",
    "    \"\"\"\n",
    "    Plots the original image and the image after applying a specific effect.\n",
    "\n",
    "    Parameters:\n",
    "    - img_before (numpy.ndarray): The original image.\n",
    "    - img_after (numpy.ndarray): The image after applying the effect.\n",
    "    - effect (str): The effect applied to the image.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4), dpi=150)\n",
    "    ax = axes.ravel()\n",
    "    ax[0].imshow(img_before, cmap=plt.cm.gray if effect in [\"Threshold\", \"Edge\"] else \"jet\")\n",
    "    ax[0].set_title(\"Original\")\n",
    "    ax[1].imshow(img_after, cmap=plt.cm.gray if effect in [\"Grayscale\", \"Threshold\", \"Edge\"]  else \"jet\")\n",
    "    ax[1].set_title(effect)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- fixing text orientation as much as possible \n",
    "\n",
    "* based on this <a href=\"https://medium.com/wearesinch/correcting-image-rotation-with-hough-transform-e902a22ad988\">article <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect the orientation of the text in image\n",
    "\n",
    "\n",
    "def hough_transforms(image):\n",
    "\t\n",
    "\tfiltered_img = ski.filters.median(image)  # Apply median filter to remove noise\n",
    "\t\n",
    "\tgray = ski.color.rgb2gray(filtered_img)  # Convert image to grayscale\n",
    "\t\n",
    "\tguess = cv2.GaussianBlur(gray, (11, 11), 0)  # Apply Gaussian blur\n",
    "\t\n",
    "\tthresh = ski.filters.threshold_otsu(guess)  # Apply Otsu's thresholding\n",
    "\t\n",
    "\tbinary = gray > thresh  # Convert image to binary\n",
    "\t\n",
    "\tedges = canny(binary)  # Detect edges using Canny edge detection\n",
    "\t\n",
    "\th, theta, d = hough_line(edges)  # Perform Hough line transform\n",
    "\t\n",
    "\taccum, angles, dists = hough_line_peaks(h, theta, d)  # Find peaks in Hough space\n",
    "\t\n",
    "\tangles = np.rad2deg(angles)  # Convert angles to degrees\n",
    "\t\n",
    "\tangle_mode = stats.mode(angles)  # Find the most common angle\n",
    "\t\n",
    "\trotation_angle = angle_mode.mode  # Get the rotation angle\n",
    "\t\n",
    "\t# i am not sure if this will work with all images  \n",
    "\tif rotation_angle < 0:\n",
    "\t\trotation_angle = 90 + rotation_angle  # Adjust rotation angle if negative\n",
    "\telse:\n",
    "\t\trotation_angle = rotation_angle - 90  # Adjust rotation angle if positive\n",
    "\t\n",
    "\treturn rotation_angle\n",
    "def hough_transforms_with_plotting_stages(image): # same as above function but with plotting the stages of the process\n",
    "\t# Create a figure and axes\n",
    "\tfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(25, 25))\n",
    "\taxes[0].imshow(image)\n",
    "\taxes[0].set_title('Original image') \n",
    "\n",
    "\t# Apply median filter to the image\n",
    "\tfiltered_img = ski.filters.median(image)\n",
    "\taxes[1].imshow(filtered_img)\n",
    "\taxes[1].set_title('Median Filter')\n",
    "\n",
    "\t# Convert the filtered image to grayscale\n",
    "\tgray = ski.color.rgb2gray(filtered_img)        \n",
    "\taxes[2].imshow(gray , cmap='gray')\n",
    "\taxes[2].set_title('Gray image')\n",
    "\n",
    "\t# Apply Gaussian blur to the grayscale image\n",
    "\tguess = cv2.GaussianBlur(gray,(11,11),0)\n",
    "\taxes[3].imshow(guess, cmap='gray')    \n",
    "\taxes[3].set_title('Gaussian Blur')\n",
    "\n",
    "\t# Apply Otsu's thresholding to obtain a binary image\n",
    "\tthresh = ski.filters.threshold_otsu(guess)\n",
    "\tbinary = gray > thresh\n",
    "\taxes[4].imshow(binary , cmap='gray')\n",
    "\taxes[4].set_title('Binary image')\n",
    "\n",
    "\t# Apply Canny edge detection to the binary image\n",
    "\tedges = canny(binary)\n",
    "\taxes[5].imshow(edges,cmap='gray')\n",
    "\taxes[5].set_title('Edges')\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "\t# Perform Hough line detection on the edges\n",
    "\th, theta, d = hough_line(edges)\n",
    "\taccum, angles, dists = hough_line_peaks(h, theta, d)\n",
    "\tangles = np.rad2deg(angles)\n",
    "\tangle_mode = stats.mode(angles)\n",
    "\trotation_angle = angle_mode.mode\n",
    "\n",
    "\t# Adjust the rotation angle to be within the range of -90 to 90 degrees\n",
    "\tif rotation_angle < 0:\n",
    "\t\trotation_angle = 90 + rotation_angle\n",
    "\telse:\n",
    "\t\trotation_angle = rotation_angle - 90\n",
    "\n",
    "\treturn rotation_angle\n",
    "\n",
    "def rotate_image(rotation_angle , image ) :\n",
    "    center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "    scale = 1.0 # zoom in or out \n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, scale)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, image.shape[:2])\n",
    "    return rotated_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test rotation on sample image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg= ski.io.imread(\"../../data/raw/fonts-dataset/Scheherazade New/42.jpeg\")\n",
    "rotation_angle  = hough_transforms_with_plotting_stages(testimg)\n",
    "newimg = rotate_image(rotation_angle, testimg)\n",
    "plot_change(testimg , newimg , effect=\"rotation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1 - Draw box on lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread(\"../../data/raw/fonts-dataset/Marhey/58.jpeg\")\n",
    "\n",
    "# Display image\n",
    "# cv2.imshow(\"Original Image\", img)\n",
    "\n",
    "# Reduce noise\n",
    "denoised_img = cv2.pyrMeanShiftFiltering(img, sp=10, sr=130)\n",
    "\n",
    "# Display denoised image\n",
    "# cv2.imshow(\"Denoised Image\", denoised_img)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(denoised_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display grayscale image\n",
    "# cv2.imshow(\"Grayscale Image\", gray)\n",
    "\n",
    "# Threshold the image\n",
    "_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Dilation to connect nearby words\n",
    "kernel = np.ones((5,100), np.uint8)  # Adjust kernel size as needed\n",
    "dilated = cv2.dilate(binary, kernel, iterations=5)\n",
    "\n",
    "# Find contours (potential text lines)\n",
    "contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter contours based on size and shape (adapt filtering based on your data)\n",
    "text_lines = []\n",
    "for cnt in contours:\n",
    "  x, y, w, h = cv2.boundingRect(cnt)\n",
    "  cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "  aspect_ratio = float(w) / h\n",
    "  if aspect_ratio > 5 and cv2.contourArea(cnt) > 1000:  # Adjust thresholds as needed\n",
    "    text_lines.append((x, y, w, h))\n",
    "\n",
    "# Draw bounding boxes around detected text lines\n",
    "for x, y, w, h in text_lines:\n",
    "  # cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "  continue\n",
    "\n",
    "# Display image with detected lines\n",
    "cv2.imshow(\"Text Lines\", img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Binarize(image):\n",
    "    \"\"\"\n",
    "    Binarizes an image using Otsu's thresholding method.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The image to binarize.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The binarized image.\n",
    "    \"\"\"\n",
    "    filtered_img = ski.filters.median(image)\n",
    "    # guess = cv2.GaussianBlur(filtered_img,(11,11),0)\n",
    "    sharp = ski.filters.unsharp_mask(filtered_img, radius=1, amount=1)\n",
    "    \n",
    "    gray = ski.color.rgb2gray(sharp)\n",
    "    thresh = ski.filters.threshold_otsu(gray)\n",
    "    binary = gray > thresh\n",
    "    # Check the color of the first pixel if its white \n",
    "    if binary[0, 0]:\n",
    "        binary = ~binary  # Invert the binarization\n",
    "    \n",
    "    \n",
    "    return binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_on_boundary_box(binaryimage) : \n",
    "\n",
    "    contours , _ = cv2.findContours(binaryimage, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #Find the minimum bounding rectangle that encloses all contours\n",
    "    x, y, w, h = cv2.boundingRect(np.concatenate(contours))\n",
    "\n",
    "    return binaryimage[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply step 1 and 2 on all images and save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image \n",
    "folder_name = [\"IBM Plex Sans Arabic\" ,\"Lemonada\" , \"Marhey\" , \"Scheherazade New\" ]\n",
    "testimg= ski.io.imread(\"../../data/raw/fonts-dataset/Scheherazade New/924.jpeg\")\n",
    "\n",
    "for j in range(0 , 4 ) : \n",
    "    for i in range(0, 1000): \n",
    "        img = ski.io.imread(\"../../data/raw/fonts-dataset/\"+folder_name[j]+\"/\"+str(i)+\".jpeg\")\n",
    "        \n",
    "        if len(np.unique(img)) == 1 : \n",
    "            continue # all image contain the same color \n",
    "\n",
    "        rotation_angle  = hough_transforms(img)\n",
    "        binarized_image = Binarize(img)\n",
    "        binarized_image = binarized_image.astype(np.uint8) * 255\n",
    "        rotated_image = rotate_image(rotation_angle, binarized_image)\n",
    "    \n",
    "        rotated_image = crop_image_on_boundary_box(rotated_image)\n",
    "        ski.io.imsave(\"../../data/processed/fonts-dataset/\"+folder_name[j]+\"/\"+str(i)+\".jpeg\", rotated_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
